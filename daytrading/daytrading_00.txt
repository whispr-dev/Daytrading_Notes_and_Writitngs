Is Stock Price Prediction a Rabbit Hole? Here’s What a Naive Model Taught Me
Linh V Nguyen
DataDrivenInvestor
Linh V Nguyen

·
Follow

Published in
DataDrivenInvestor

·
6 min read
·
Sep 11, 2024
241


5





A Beginner’s Exploration of Stock Price Forecasting and Why It’s Harder Than It Looks.


Image by Author
Introduction
“Lemme build LSTM to predict stock price.”

I’ve heard this claim more times than I can count. But here’s the thing: I once believed it, too. Fresh out of the Deep Learning course in Coursera a few years ago, I thought I could outsmart the market. Spoiler alert: I couldn’t.

Stock price prediction is often the entry point for many data enthusiasts. After all, stock prices are time-series data, and we have well-established tools and packages that excel at time-series forecasting. A quick Google search for “LSTM stock price prediction” will return thousands of blogs, from different network architectures to various feature engineering techniques.

But here’s the million-dollar question: is it possible to predict the next day’s stock price with any meaningful accuracy? Let’s dive into a simple experiment with META’s closing prices to see just how far (or not) we can get.

Naive Forecasting
Let’s use a naive approach: tomorrow’s price will be exactly the same as today’s.

Yes, that’s simple.

But why start with something so basic? It’s simple: the naive model sets the benchmark. Before diving into any complexity, we need to do a reality check. If we can’t beat this, all the fancy models won’t mean much.

To illustrate, I set all forecasts to the value of the last observation. For the META closing price context, this can be achieved by merely getting yesterday’s Close Price in a separate column. This value becomes the actual value for the current day. The next step is to populate the forecasted value for each day.

First, let’s grab the stock data from Yahoo Finance, and we must install the Yahoo Finance library: pip install yfinance. If you’re following along, ensure you’ve installed the necessary libraries (you’ll need numpy, pandas, matplotlib, and sklearn)

After that, here’s the code that downloads the data, makes the naive prediction, and shifts the target value:

import numpy as np
import pandas as pd
import yfinance as yf
import matplotlib.pyplot as plt
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, median_absolute_error

# Download META data from yfinance
ticker = 'META'
meta_data = yf.download(ticker, start='2016-01-01', end='2024-01-01')

# Shift the target (predicting t+1 Close price)
meta_data['Target'] = meta_data['Close'].shift(-1)

# Naive prediction: next day's price = today's price
meta_data['Naive_Pred'] = meta_data['Close']

display(meta_data[['Naive_Pred', 'Target']])

Image by Author
This is what we’ve got: the Naive_Pred is the exact value of yesterday’s Target. To judge how good (or bad) our predictions are, we need to rely on a few key metrics, including:

Mean Absolute Error (MAE): measures the average of the absolute differences between predicted and actual values. All errors are equally weighted, making it straightforward but insensitive to outliers.

Image by Author
Root Mean Squared-Error (RMSE): the square root of the average of squared differences between actual and predicted values. Squaring penalizes more significant errors, so RMSE is more sensitive to outliers than MAE.

Image by Author
Mean Absolute Percentage Error (MAPE): normalizes the error as a percentage of the actual value, which makes it scale-independent and helpful in comparing performance across different datasets. However, it has limitations when actual values are near 0 (MAPE would be exaggerated).

Image by Author
Symmetric Mean Absolute Percentage Error (SMAPE): a variation of MAPE that accounts for both actual and predicted values in the denominator. It avoids the issue of MAPE being heavily exaggerated when actual values are close to 0.

Image by Author
R² (R-squared): measures the proportion of the variance in the dependent variable that is predictable from the independent variable(s). It ranges from 0 to 1, and the closer to 1 the value is, the better the model.

Image by Author
Where:


Image by Author
Now, let’s calculate the errors. Here’s how to do it in the code and visualize the plots:

meta_data['Error'] = meta_data['Target'] - meta_data['Naive_Pred']

# Drop any rows with NaN values, due to shifting
meta_data = meta_data.dropna()

y_true = meta_data['Target']
y_pred = meta_data['Naive_Pred']

# Compute error metrics
mae = mean_absolute_error(y_true, y_pred)
rmse = np.sqrt(mean_squared_error(y_true, y_pred))
mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100
smape = np.mean(np.abs(y_true - y_pred) / (np.abs(y_true) + np.abs(y_pred)) * 2) * 100
r2 = r2_score(y_true, y_pred)

# Print metrics
print(f"| RMSE | MAE  |  MAPE | SMAPE | R-squared |")
print(f"|------|------|-------|-------|-----------|")
print(f"| {rmse:.2f} | {mae:.2f} | {mape:.2f}% | {smape:.2f}% |   {r2:.3f}   |")

fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 9), sharex=True)

# Actual vs Predicted
ax1.plot(meta_data.index, y_true, label='Actual Prices', color='blue')
ax1.plot(meta_data.index, y_pred, label='Naive Prediction $(Y(t+1) = Y(t))$', color='orange', alpha=0.7, linestyle='dashdot')
ax1.set_title('META Stock (Close Price): Actual vs Naive Model Prediction', fontsize=20)
ax1.set_ylabel('Price')
ax1.legend(loc='best')
ax1.grid(True)

# Error
ax2.plot(meta_data.index, meta_data['Error'], color='red')
ax2.set_title('Prediction Error (Actual - Prediction)', fontsize=20)
ax2.set_xlabel('Date')
ax2.set_ylabel('Error')
ax2.legend(loc='best')
ax2.grid(True)

plt.tight_layout()
plt.show()
So, How Did We Do?
The visualization:


Image by Author
and the output:


Image by Author
RMSE = 6.73 and MAE = 4.24:

This indicates that, on average, our predictions are off by $4–6
RMSE penalizes more significant errors more heavily, suggesting that there are some significant outliers in the predictions, as the plot clearly shows.
MAPE = 2.21% and SMAPE = 2.21%:

This suggests that, on average, the model’s predictions are within ~2 % of the actual stock price. Also, the errors are pretty symmetrically distributed above and below the exact values.
R-squared: 0.99

This means that ~99% of the variance in the stock price is explained by the naive model.
These numbers tell an interesting story, hinting that knowing today’s price tells you almost everything you need to know about tomorrow’s price. Obviously, without any actual model, we can confidently say tomorrow’s price will likely be very close to today’s. But here’s the catch: this isn’t magic; it’s just how stocks behave in the absence of dramatic events.

Why Is This So?
It’s all about autocorrelation. Like many things in nature, stock prices tend to be similar from one day to the next. Without unexpected events (like a global pandemic or political upheaval), the stock will not likely jump from $300 to $400 overnight.

Is Predicting Stock Prices Worth It?
Well, that’s not easy. Stock prices reflect all available information, a principle known as the Efficient Market Hypothesis. This makes it difficult to “beat the market” through prediction alone.

So, are we chasing a rabbit down a hole with stock price prediction? Yes and No. More advanced techniques might give a slight edge. However, as we’ve seen, we can randomly claim that tomorrow’s price will be the same as today, and it’s still reasonably accurate.

It’s just different from what most people think it is. I hypothesize that the real challenge lies elsewhere — predicting trends, responding to external events, or capitalizing on high-frequency data. And let’s not forget: trading costs, including brokerage fees, can quickly erode any marginal gains. These factors mentioned above are the actual battlegrounds.

So the next time someone claims they can predict stock prices, remember our simple experiment. Ask them if they’ve beaten yesterday’s price. Most haven’t. If they can, well… maybe they have cracked the code. But don’t let this discourage us from exploring. The journey of understanding markets, and especially time-series data, is as valuable as any destination.

Thanks for reading