Predicting Market Trends Using Stacked LSTM Models
Analyzing Historical Data with Neural Networks for Improved Market Forecasting
Jermaine Matthew
Jermaine Matthew

·
Follow

21 min read
·
Jul 30, 2024
231


6





The present study focuses on predicting stock prices through the utilization of Stacked Long Short-Term Memory (LSTM) networks. This method leverages advanced neural network architectures to analyze and forecast market trends based on historical price data.

Stock price forecasting is a critical aspect of financial analysis, enabling investors and financial professionals to make informed decisions. Stacked LSTM networks, known for their ability to capture temporal dependencies, are particularly suited for this task. By stacking multiple LSTM layers, the model enhances its capacity to learn complex patterns within the time series data.

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM
This code snippet introduces several libraries that are widely utilized for data analysis and machine learning within the Python programming environment.

Pandas is imported as pd, providing essential functionality for data manipulation and analysis, especially for handling structured data such as DataFrames. This capability is crucial for preparing datasets for modeling.

NumPy is imported as np, and it serves as a fundamental package for numerical computations in Python. It enables operations on arrays and matrices, which are frequently necessary for data manipulation and mathematical functions within machine learning models.

Matplotlibs pyplot is imported as plt, a library designed for creating static, interactive, and animated visualizations in Python. This library plays a vital role in data visualization, allowing users to generate graphs and charts to gain insights into the data and evaluate model performance.

MinMaxScaler, sourced from the sklearn.preprocessing module, is leveraged to scale features within a defined range, typically between 0 and 1. This scaling process is a significant preprocessing step in machine learning as it enhances the speed and accuracy of model convergence when processing input data.

The Keras API from TensorFlow is employed to construct neural network models, specifically the Sequential model. This approach facilitates the development of deep learning architectures. The model consists of various layers, including Dense layers, which are fully connected neural network layers, as well as LSTM layers, which represent Long Short-Term Memory layers that are particularly effective for sequence prediction tasks, such as time series analysis or natural language processing.

plt.plot(df_close)
plt.show()

This code is designed for data visualization in Python, specifically to plot a line graph representing time series data contained within a DataFrame object named df_close.

The primary function of this code is to create a visual representation, specifically a line plot, which illustrates the values stored in the df_close DataFrame. Such visualizations are widely utilized in data analysis to identify trends over time or to compare different datasets effectively.

This code operates through the use of the Matplotlib library, initiated by the command plt.plot(df_close). This command generates a plot using the data from the df_close DataFrame, where the x-axis typically represents time — provided that the DataFrame’s index is time-based — and the y-axis displays the corresponding values. The inclusion of the plt.show() function is necessary to render and display the created plot; without this, the plot may not appear in certain environments.

The significance of this code lies in its ability to facilitate data visualization, which is essential in data analysis. Visualizing data enhances comprehension and interpretation of trends, patterns, and anomalies within a dataset. By plotting df_close, users can extract insights that might not be as readily apparent through examination of raw numerical data alone. This process ultimately aids in making informed decisions based on the visual depiction of the data.

MinMax scaling is a preprocessing technique that is particularly relevant when working with Long Short-Term Memory (LSTM) networks, given their sensitivity to the scale of input data.

Typically, LSTM models perform better when the input features are normalized to a specific range. MinMax scaling transforms the data by compressing its range to fall between a defined minimum and maximum value, usually 0 and 1. This adjustment helps to ensure that the various input features contribute equally to the learning process, thus improving the performance and stability of the model.

In employing MinMax scaling, careful consideration must be given to the impact it may have on the patterns within the data. Although it is effective in standardizing the input values, it is essential to retain the underlying relationships present in the original dataset. Therefore, when utilizing LSTM networks, integrating MinMax scaling can lead to enhanced model accuracy and efficiency.

scaler = MinMaxScaler(feature_range=(0,1))
df_close = scaler.fit_transform(np.array(df_close).reshape(-1,1))
This code snippet demonstrates the application of feature scaling on a dataset, specifically utilizing the Min-Max scaling technique provided by the Scikit-learn library. The objective of this procedure is to transform the values in the df_close dataset, which likely consists of closing stock prices or similar numerical data, into a standardized range from 0 to 1.

The process begins with the initialization of a MinMaxScaler object, which is configured with a feature range of (0, 1). This allows the transformed data to be rescaled so that the minimum value becomes 0 and the maximum value becomes 1. Such initialization is a crucial first step in the scaling process.

Following this, the original data, df_close, is reshaped into a two-dimensional array. This transformation is necessary because the scaler requires data in a two-dimensional format, comprising samples and features, even if there is only a single feature, as is the case with the closing price dataset.

Next, the fit_transform method is employed on the scaler object using the reshaped data. This method calculates the minimum and maximum values of the original dataset, applies the scaling transformation to ensure the data falls within the specified range, and returns the normalized values.

The use of this code is vital in the context of data preprocessing, particularly within machine learning and statistical analysis. Normalization ensures that features contribute equivalently to distance calculations in algorithms sensitive to data scale, such as K-nearest neighbors and gradient descent optimization methods. Moreover, scaling can enhance the convergence speed of certain algorithms, thereby expediting the training process and improving efficiency. Additionally, it reduces the impact of outliers, preventing them from negatively influencing the models learning process.

train_size = int(len(df_close)*0.65)
test_size = len(df_close) - train_size
train_data = df_close[0:train_size,:]
test_data = df_close[train_size:,:]
This code serves to prepare datasets for the training and testing of machine learning models, particularly in the context of time series data, such as financial information represented by the variable name df_close.

The primary function of the code is to compute the proportions of the dataset to be used for training and testing. Specifically, it designates 65% of the total dataset as the training portion and allocates the remaining 35% for testing. This division enables the program to effectively evaluate the models performance on unseen data.

To implement this division, the code first determines the size of the training dataset, referred to as train_size, which is calculated as the integer value representing 65% of the total number of rows within df_close. The size of the testing dataset, termed test_size, is then derived by subtracting train_size from the overall number of rows, ensuring that all data within df_close is utilized. Ultimately, the code creates two distinct segments by slicing the DataFrame: one designated for training and the other for testing purposes through indexing.

The rationale behind utilizing this code is centered on the concepts of model training and validation. By partitioning the dataset, it allows for the training of the model on one subset while evaluating its efficacy on another. This approach provides insights into the models ability to generalize when confronted with data it has not encountered previously.

Moreover, separating the training data from the testing data helps mitigate the risk of overfitting. Training on a unique dataset reduces the likelihood of the model merely memorizing the input data — a phenomenon that could detrimentally affect performance when applied to new data. Testing the model on a different set enables a robust assessment of its accuracy and overall effectiveness.

In the context of time series analysis, maintaining the temporal structure of the data is essential. This code adheres to that principle by assigning the initial segment of the dataset for training and reserving the subsequent segment for testing. This method effectively simulates realistic scenarios in which historical data is applied to forecast future outcomes.

plt.figure(figsize=[15,5])
plt.subplot(121)
plt.plot(train_data)
plt.title('Train Data')
plt.subplot(122)
plt.plot(test_data)
plt.title('Test Data')
plt.show()

This code serves the purpose of visualizing two distinct sets of data: the training data and the test data. It generates a figure that presents both datasets side by side in a coherent manner.

Initially, the code sets the dimensions of the figure to ensure a wider display, which facilitates easy viewing of both plots without any overlap. The figure is subsequently divided into two subplots. The first subplot is reserved for the training data, where a line graph illustrates the values of the training dataset over time or another relevant index. The second subplot mirrors this arrangement but focuses on the test data, again employing a line graph for representation. Each subplot is appropriately titled to clarify which dataset is being showcased, thereby assisting viewers in interpreting the information presented. Ultimately, the combined visual output is displayed for the user.

The utilization of this code is significant for various reasons. It enables a visual comparison between the training and test datasets, which is vital in the fields of machine learning and statistics for evaluating how effectively a model may perform on previously unseen data. Through visual analysis of the patterns, trends, and distributions in both datasets, one can gain insights into the models potential for generalization and identify issues such as overfitting or underfitting. In summary, visualization constitutes an essential component of data analysis and interpretation, rendering this code indispensable for effective data exploration.

The training of the model encompasses information available until October 2023. This means that any developments or changes occurring after this date are not reflected in the models knowledge. Consequently, the models understanding and responses are limited to the data and events up to that specified point in time.

def create_dataset(dataset, time_step=1):
    dataX, dataY = [], []
    for i in range(len(dataset)-time_step-1):
        dataX.append(dataset[i:(i+time_step),0])
        dataY.append(dataset[(i+time_step),0])
    
    return np.array(dataX), np.array(dataY)
The code defines a function named create_dataset, which is intended to prepare a time series dataset for the training of machine learning models, especially for tasks related to forecasting or regression.

The function accepts a dataset, which should generally be a multi-dimensional array, such as a NumPy array, as well as a parameter called time_step. This parameter indicates the number of preceding time steps to be used in predicting the next value in the series.

Initially, the function establishes two empty lists: dataX and dataY. The list dataX is designated to hold sequences of input data, while dataY is meant to contain the corresponding output values that follow each sequence.

The function proceeds to iterate through the dataset. For each point in the dataset, it extracts a slice of the last time_step values to form an input sequence, which is subsequently added to dataX. The output value, representing the next value in the series following the input sequence, is then appended to dataY.

Once the entire dataset has been processed, the function converts both dataX and dataY into NumPy arrays and returns them.

time_step = 100
train_x, train_y = create_dataset(train_data, time_step)
test_x, test_y = create_dataset(test_data, time_step)
This code snippet is designed to facilitate the preprocessing of data for tasks involving time series machine learning or deep learning. The script establishes a variable that denotes the time step, set at 100, which is then utilized to transform two distinct datasets: one for training and the other for testing.

The preprocessing is executed through a function designed to segment the time series data, referred to as create_dataset. This function operates by organizing the train_data and test_data according to the specified time step. For each point within the dataset, it generates a corresponding label or output based on a sequence of preceding values defined by the time step. In essence, it creates overlapping windows of data points that allow for better analysis.

Applying this function to both the training and testing datasets ensures that they are consistently formatted, which is critical for developing a predictive model. This method allows each input sequence to be paired with its respective output, enabling the model to discern the relationship between them effectively.

Moreover, it is important to note that many machine learning models, particularly recurrent neural networks (RNNs) and long short-term memory networks (LSTMs), require the data to be structured in a particular format. This structure is crucial for these models to effectively comprehend temporal relationships. Thus, this preprocessing step is indispensable for enabling the models to learn from data that is dependent on time.

train_x = train_x.reshape(train_x.shape[0],train_x.shape[1],1)
test_x = test_x.reshape(test_x.shape[0],test_x.shape[1],1)
The code is designed to reshape the training and testing datasets, referred to as train_x and test_x. These datasets typically contain the input data required for a machine learning model and are organized as arrays or matrices.

The primary aim of this code is to alter the structure of each dataset to acquire three dimensions. Specifically, the reformulated shape maintains the original number of samples, represented by train_x.shape[0] for the training set and test_x.shape[0] for the testing set. It preserves the original count of features or time steps in the second dimension, indicated by train_x.shape[1] or test_x.shape[1]. The third dimension is set to a size of one.

This reshaping process is often necessary for certain neural network architectures, particularly those that process sequential data, such as recurrent neural networks (RNNs) and convolutional neural networks (CNNs). These models generally require input data in a three-dimensional format. The dimensions typically correspond to the number of samples, the number of time steps or features, and the number of channels, with channels being defined as one in this context.

train_x.shape, train_y.shape, test_x.shape, test_y.shape

This code is utilized to obtain the dimensions of four distinct datasets: train_x, train_y, test_x, and test_y. Each of these variables plays a significant role in the machine learning workflow.

The variable train_x typically holds the feature data for training, encompassing the input variables from which the model will learn. In contrast, train_y contains the target or label data corresponding to train_x, representing the desired outputs for those input features. The test_x variable includes the feature data intended for testing, which will evaluate the trained models performance on new, unseen data. Meanwhile, test_y stores the target or label data for testing, serving as the benchmark against which the models predictions on test_x will be compared.

By invoking the .shape attribute on these arrays, one can ascertain their dimensions, which indicate the number of rows and columns. This information is vital for several reasons. Firstly, it facilitates an understanding of the data structure, enabling verification that the data is organized correctly and that the number of samples and features is appropriately aligned between the input and output datasets.

Secondly, knowing the shape of the datasets is crucial for model input validation, as it confirms that they conform to the expected dimensions required by the machine learning model before training can commence. Additionally, in the event of issues arising during training or evaluation, examining the shapes of these datasets is often a preliminary step to identify any potential mismatches or errors in data preparation.

model = Sequential()
model.add(LSTM(50, return_sequences=True, input_shape=(100,1)))
model.add(LSTM(50, return_sequences=True))
model.add(LSTM(50))
model.add(Dense(1))
This code establishes a neural network model utilizing a Sequential architecture, specifically tailored for the analysis of sequential data, such as time series or ordered data points.

The model features three Long Short-Term Memory (LSTM) layers along with a Dense layer. LSTM layers are particularly suitable for tasks that rely on contextual information from prior time steps, thanks to their proficiency in retaining information throughout various time intervals.

In terms of layer configuration, the first LSTM layer is composed of 50 units and is set to return sequences. This means that it produces a complete sequence of outputs for each time step, enabling subsequent layers to process these sequences. The second LSTM layer mirrors this configuration, also containing 50 units and returning sequences, allowing for further processing of the output generated by the preceding LSTM layer. The third LSTM layer differs in that it does not return sequences; instead, it generates a singular output value, which is typically employed in regression tasks or final predictions. Following these layers, the Dense layer comprises one unit that delivers the model’s final output, often used to generate predictions based on the LSTM layers outcomes.

Regarding input requirements, the model is structured to accept sequences that encompass 100 time steps, with each time step featuring a single attribute, thereby creating an input shape of (100, 1).

The primary objective of this code is to implement a model suitable for making predictions grounded in sequential data. Such applications can include stock price forecasting, weather prediction, or tasks in natural language processing. The inclusion of LSTM layers enables the model to effectively capture temporal dependencies within the data, enhancing its capability to recognize patterns over time.

model.compile(loss='mean_squared_error', optimizer='adam')
This code serves a crucial role in the preparation of a machine learning model, especially within the domain of deep learning utilizing frameworks such as TensorFlow or Keras. It establishes the foundation for training the model by defining both the loss function and the optimization algorithm.

The loss parameter is crucial as it determines the metric utilized to assess the models performance during the training phase. In this instance, the mean_squared_error is selected, which is a standard choice for regression tasks. This metric computes the average of the squared differences between the predicted values and the actual values. Consequently, a lower mean squared error reflects a better alignment of the model with the training data.

The optimizer parameter specifies the algorithm employed to adjust the models weights throughout the training process. In this case, the adam optimizer is indicated, which stands for Adaptive Moment Estimation. This optimization method is favored for its ability to merge the advantages of two variations of stochastic gradient descent. It individually adapts the learning rate for each parameter based on the estimations of the first and second moments of the gradients, thereby enhancing the efficiency and stability of the learning process.

model.summary()

The command model.summary() is commonly employed in machine learning frameworks such as TensorFlow/Keras and PyTorch. When executed, it produces a comprehensive summary of the models architecture. This summary offers valuable information regarding the various layers that comprise the model.

It details the types of layers utilized, including but not limited to convolutional layers, dense layers, and recurrent layers. Additionally, it provides insight into the output shapes generated by each layer, which is instrumental in understanding the flow of data throughout the model. The summary also enumerates the total number of parameters, including weights and biases, within each layer and across the entire model. This information aids in evaluating the complexity and capability of the model.

Furthermore, the summary differentiates between trainable and non-trainable parameters. This distinction is significant, particularly in models that leverage techniques such as transfer learning, as it clarifies which parameters can be adjusted during training and which remain fixed.

The utility of this summary extends to various aspects of model development and research. It assists in debugging by enabling users to confirm the accurate construction of the model, ensuring proper connectivity among layers and alignment of dimensions. It also facilitates model evaluation by providing an overview of complexity, helping to determine whether the model is suitable for the intended task and assessing risks of underfitting or overfitting the data.

model_history = model.fit(train_x, train_y, 
                          validation_data=(test_x, test_y), 
                          epochs=100, batch_size=64)

This code is intended for the training of a machine learning model utilizing a specified dataset. It is structured to optimize the model with respect to the training data, referred to as train_x and train_y, while also evaluating its performance on an independent validation dataset, denoted as test_x and test_y.

The first step in this process involves model fitting. The fit function is called on a model object, initiating the training sequence. During this phase, the model learns to correlate input data, captured in train_x, with corresponding output labels found in train_y, as it iteratively modifies its parameters.

Validation plays a critical role in assessing model performance. By incorporating validation data, the code enables the model to evaluate its capabilities on data that was not included in the training phase. This practice is essential for monitoring the models ability to generalize to new, unseen instances.

The concept of epochs is significant in this context. The epochs parameter indicates the number of times the model will traverse the entirety of the training dataset, set to 100 in this instance. This repetition gives the model several opportunities to learn from the data, allowing it to refine its weights to minimize prediction errors effectively.

Another important parameter is the batch size. This parameter specifies the number of samples from the training dataset that will be processed collectively before the model adjusts its parameters. A batch size of 64 implies that the training data is divided into groups of 64 samples, which the model processes sequentially. This strategy may help in optimizing memory usage and can potentially accelerate the convergence of the training process.

The rationale for employing this code encompasses several critical aspects. Training the model is fundamental to establishing a system capable of accurately predicting or classifying data. Moreover, using validation data is vital for ensuring that the model does not overfit, which guarantees its effectiveness in practical applications beyond the training dataset. Additionally, the ability to adjust hyperparameters such as the number of epochs and batch size allows practitioners to fine-tune the training regimen, thereby enhancing results according to their specific datasets and objectives.

plt.figure(figsize=[10,6])
plt.plot(model_history.history['loss'], label='train loss')
plt.plot(model_history.history['val_loss'], label='val loss')
plt.legend()
plt.show()

This code serves the purpose of visualizing the training process of a machine learning model, specifically by illustrating the loss values across various epochs during the training phase.

To elaborate, the code initiates by creating a new figure for the plot, which is defined with a specific size. It subsequently represents two lines on this figure: one corresponds to the training loss, while the other represents the validation loss of the model. These loss values are derived from a history object that monitors the performance metrics of the model at the conclusion of each training epoch. The legend included in the visualization facilitates the differentiation between training and validation loss, thereby enhancing the interpretation of the results. Ultimately, the plot is rendered for viewing.

The significance of this code lies in the fact that monitoring the loss values is essential for evaluating the learning efficacy of the model. Analyzing the trends of both training and validation losses can provide insights into whether the model is exhibiting overfitting, underfitting, or is performing optimally. Such information is vital for making necessary adjustments to the models architecture, hyperparameters, and training procedures to enhance its overall performance.

Forecasting refers to the process of making predictions about future events based on historical data and analyses. This practice is widely employed across various sectors to guide decision-making and strategic planning.

Accurate forecasting is vital as it helps organizations anticipate market trends, consumer behavior, and potential challenges. By analyzing past patterns and current conditions, businesses can develop informed strategies that enhance their operations and improve overall performance.

train_predict = model.predict(train_x)
test_predict = model.predict(test_x)
This code snippet is employed within the realm of machine learning, specifically for the purpose of making predictions utilizing a trained model. The code is divided into two primary segments, each responsible for generating predictions on distinct datasets.

The first element of the code involves making predictions on the training dataset. The line train_predict = model.predict(train_x) accomplishes this task. This step serves dual purposes: it enables an assessment of the models learning capability based on the training data, and it provides valuable insights regarding the models potential performance on data that has not been encountered before.

The second part of the code involves predictions on a separate testing dataset, as demonstrated by the line test_predict = model.predict(test_x). This step is critical for evaluating the models generalization ability, which refers to its performance on unseen data.

In this context, the term model signifies a machine learning model that has been previously trained using the training dataset. The predict() method utilizes the patterns learned during the training phase and applies them to the provided input data, either train_x or test_x, resulting in output predictions.

The rationales behind utilizing this code are manifold. Conducting predictions on both the training and testing datasets allows practitioners to determine the models accuracy and identify potential concerns, such as overfitting, where the model excels on training data yet underperforms when faced with unseen data. Additionally, scrutinizing the predictions aids in fine-tuning the model, understanding its capabilities and limitations, and guiding decisions regarding its deployment or further modification.

trainPredictPlot = np.empty_like(df_close)
trainPredictPlot[:, :] = np.nan
trainPredictPlot[time_step:len(train_predict)+time_step,:] = train_predict

testPredictPlot = np.empty_like(df_close)
testPredictPlot[:, :] = np.nan
testPredictPlot[len(train_predict) + (time_step*2) +1:len(df_close)-1, :] = test_predict

plt.figure(figsize=[12,8])
plt.plot(scaler.inverse_transform(df_close))
plt.plot(scaler.inverse_transform(trainPredictPlot))
plt.plot(scaler.inverse_transform(testPredictPlot))
plt.show()


The code is crafted to illustrate the predictions produced during the training and testing phases of a machine learning model, particularly in the realm of time series data, including stock prices and similar financial indicators.

Initially, the code establishes two empty arrays, named trainPredictPlot and testPredictPlot, mirroring the dimensions of the original dataset, referred to as df_close. These arrays are initialized with NaN (Not a Number) values, ensuring that areas devoid of predictions do not interfere with the resulting visualization.

The subsequent step involves populating the trainPredictPlot array with the predictions derived from the training dataset. This process incorporates an offset corresponding to a defined time_step, which accounts for the inherent delay associated with generating predictions in the context of time series data.

In a parallel manner, the code fills the testPredictPlot array with the predictions from the testing phase. Here, an additional offset is applied, based on the duration of the training predictions. This adjustment guarantees that the predictions align accurately with the corresponding time period following the training.

In the final phase, the code employs Matplotlib to generate a plot representing the original time series data, which has been inverse transformed for improved interpretability, alongside the training and testing predictions. The plotting process is executed within a specified figure size to enhance clarity.

This code utilizes NumPy for array creation and manipulation, allowing for the visualization of data without altering the original dataset. The inverse transformation via the scaler is a significant aspect, as it translates normalized data back to its original scale, thereby rendering the visualization meaningful and comprehensible.

The rationale for employing this code is multifaceted. It facilitates a visual comparison between actual observed values and predicted values, which is essential for evaluating the accuracy and effectiveness of the machine learning model. Furthermore, by visually assessing how well the model predictions align with actual data, one can better understand the models ability to capture trends, seasonal patterns, as well as identify any inconsistencies that may suggest overfitting or underfitting.

Lastly, the visual representation of results is often requisite for reports or presentations, enabling stakeholders to easily comprehend the efficacy of the predictive model.

temp_input = list(x_input)
temp_input = temp_input[0].tolist()
temp_input

The code snippet you provided carries out a sequence of operations on an input variable referred to as x_input. The first operation involves converting x_input into a list, designated as temp_input. This transformation is beneficial when x_input originates from an array-like structure, such as a numpy array, as it allows for easier iteration and manipulation within a standard Python list framework.

Next, the code retrieves the first element of temp_input by accessing it using the index 0 and subsequently invokes the tolist() method on this element. This indicates that the first element is likely another array-like structure, potentially a numpy array. The use of tolist() facilitates the conversion of this element into a conventional list format. This step enhances the flexibility for data handling, especially if the first element contains critical information.

The final operation outputs temp_input, which now comprises the list derived from the initial element of the original input. This effectively results in a standard Python list that can be used for further operations

output = []
days = 517
for i in range(days):
    print('start')
    x_input = np.array(temp_input[i:])
    print(f'{i} day input {x_input}')    
    x_input = x_input.reshape((1, time_step, 1))
    yhat = model.predict(x_input, verbose=0)
    print(yhat)
    temp_input.extend(yhat[0].tolist())
    output.extend(yhat[0].tolist())

This code snippet is designed for making predictions with a machine learning model, likely associated with time series forecasting.

Initially, an empty list called output is established to store the results of the predictions. A variable named days is assigned a value of 517, representing the number of days for which predictions will be generated.

Subsequently, a loop is initiated that continues for the duration of the specified number of days. In each iteration, several actions are performed. A message is first printed to indicate the commencement of predictions for the current day. The code then retrieves a segment of the input data, referred to as temp_input, which begins from the current day index and serves as input for the model.

The shape of the input data is adjusted through a reshaping process, which is essential for the model to accurately interpret the input dimensions. This transformation aligns the data with the expected format required by the model, consisting of one sequence, a defined number of time steps, and a single feature.

The model then generates a prediction based on the reshaped input. The inclusion of the parameter verbose=0 prevents any extraneous output during the prediction phase, promoting both efficiency and clarity. Following the prediction, the estimated value is printed, providing real-time feedback regarding the models forecast for that specific day. Furthermore, this predicted value is incorporated into both temp_input and output. By adding it to temp_input, the code ensures that the subsequent days input data includes this forecasted value, facilitating a continuous forecasting process.

The rationale behind this code lies in its application for time series forecasting, which is crucial in situations requiring future value predictions based on historical data, such as stock prices, weather patterns, and sales forecasts. This iterative approach to prediction allows for the generation of forecasts that evolve over time, as each new prediction integrates previous results. This method proves especially beneficial in dynamic environments where predictions are subject to change.